{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d4am.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1 Week 2 Day 4 AM - Data Wrangling in SQL"
      ],
      "metadata": {
        "id": "1BGRTGMq85VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition"
      ],
      "metadata": {
        "id": "jJdhwzsD9Bar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Data Wrangling ?\n",
        "\n",
        "1. Data wrangling or data munging, is the process of **transforming** and **mapping** data from one \"raw\" data-source data-form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.\n",
        "\n",
        "2. We can simply say that the data wrangling process is a **method of data cleaning and data preparation** by converting it from one form to a more understandable form mainly for preliminary data analytics.\n",
        "\n",
        "3. The process of transformation such as :\n",
        "  * Data Exploration\n",
        "  * Data Preparation\n",
        "  * Data Cleaning\n",
        "  * Data Validation \n",
        "  * Data Enrichment\n",
        "  * etc.\n",
        "\n",
        "4. This might mean modifying all of the values in a given column in a certain way, or merging multiple columns together. \n",
        "\n",
        "5. The necessity for data wrangling is often a biproduct of poorly collected or presented data. Data that is entered manually by humans is typically fraught with errors; data collected from websites is often optimized to be displayed on websites, not to be sorted and aggregated.\n",
        "\n",
        "6. You can think Data Wrangling is like Preprocessing in Machine Learning. But, we are using SQL to cleaning the data rather than using Python.\n",
        "\n",
        "7. You can use DDL and DML syntax that you’ve already learn in previous phase."
      ],
      "metadata": {
        "id": "e2AvK7jf9EAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Dataset\n",
        "\n",
        "For this tutorial, you will create several tables."
      ],
      "metadata": {
        "id": "ddJy6Wt8jdv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT NOTES :**\n",
        "1. For this DDL and DML that will explain in this notebook, **it runs smoothly in MariaDB**. So, it will be nice if you have MariaDB in your computer.\n",
        "\n",
        "2. **If you don't have MariaDB in your computer, you can still follow the instructions with online MariaDB. Go to [sqliteonline.com](https://sqliteonline.com/)**. In the left menu, choose MariaDB and click `Click to connect`.\n",
        "\n",
        "3. Sometimes, if you try to run the code with non MariaDB, it will error for several reasons. Mainly, this is because different way of writing a particular syntax. For example : for automatically write integer \n",
        "  * In MariaDB, you must write `AUTO INCREMENT`.\n",
        "  * In SQLite, you must write `AUTOINCREMENT`."
      ],
      "metadata": {
        "id": "7-sENLHf_SGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table `crunchbase_companies_clean_data`\n",
        "\n",
        "Data Definition Language (DDL)\n",
        "```\n",
        "CREATE TABLE crunchbase_companies_clean_data (\n",
        "    permalink VARCHAR(50),\n",
        "    name VARCHAR(50),\n",
        "    homepage_url VARCHAR(50),\n",
        "    category_code VARCHAR(50),\n",
        "    funding_total_usd BIGINT,\n",
        "    status VARCHAR(20),\n",
        "    country_code VARCHAR(5),\n",
        "    state_code VARCHAR(5),\n",
        "    region VARCHAR(50),\n",
        "    city VARCHAR(50),\n",
        "    funding_rounds INT,\n",
        "    founded_at VARCHAR(20),\n",
        "    founded_at_clean VARCHAR(20),\n",
        "    id INT NOT NULL PRIMARY KEY AUTO_INCREMENT\n",
        "    );\n",
        "```\n",
        "\n",
        "Data Manipulation Language (DML) : You can see the data for DML in this [link](https://github.com/ardhiraka/FSDS_Guidelines/blob/master/p1/w2_new/d4am-extra/crunchbase_companies_clean_data.sql).\n"
      ],
      "metadata": {
        "id": "yqi00KyvjpEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table `sf_crime_incidents_2014_01`\n",
        "\n",
        "Data Definition Language (DDL)\n",
        "```\n",
        "CREATE TABLE sf_crime_incidents_2014_01 (\n",
        "    id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n",
        "    incidnt_num BIGINT,\n",
        "    category VARCHAR(30),\n",
        "    descript VARCHAR(100),\n",
        "    day_of_week VARCHAR(10),\n",
        "    date DATETIME,\n",
        "    time VARCHAR(5),\n",
        "    pd_district VARCHAR(20),\n",
        "    resolution VARCHAR(20),\n",
        "    address VARCHAR(50),\n",
        "    lon FLOAT,\n",
        "    lat FLOAT,\n",
        "    location VARCHAR(50)\n",
        "    );\n",
        "```\n",
        "\n",
        "Data Manipulation Language (DML) : You can see the data for DML in this [link](https://github.com/ardhiraka/FSDS_Guidelines/blob/master/p1/w2_new/d4am-extra/sf_crime_incidents_2014_01.sql).\n"
      ],
      "metadata": {
        "id": "4UeUottaB6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table `dc_bikeshare_q1_2012`\n",
        "\n",
        "Data Definition Language (DDL)\n",
        "```\n",
        "CREATE TABLE dc_bikeshare_q1_2012 (\n",
        "    id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n",
        "    duration VARCHAR(20),\n",
        "    duration_seconds INT,\n",
        "    start_time DATETIME,\n",
        "    start_station VARCHAR(70),\n",
        "    start_terminal INT,\n",
        "    end_time DATETIME,\n",
        "    end_station VARCHAR(70),\n",
        "    end_terminal INT,\n",
        "    bike_number VARCHAR(10),\n",
        "    rider_type VARCHAR(20)\n",
        "    );\n",
        "```\n",
        "\n",
        "Data Manipulation Language (DML) : You can see the data for DML in this [link](https://github.com/ardhiraka/FSDS_Guidelines/blob/master/p1/w2_new/d4am-extra/dc_bikeshare_q1_2012.sql)."
      ],
      "metadata": {
        "id": "gGVUJ0LqFASE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Exploration"
      ],
      "metadata": {
        "id": "rrCb8r6H9fBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you need to know about your dataset. You learned that certain functions work on some data types, but not others. \n",
        "\n",
        "For example, `COUNT` works with any data type, but `SUM` only works for numerical data. In order to use `SUM`, the data must appear to be numeric, but it must also be stored in the database in a numeric form.\n",
        "\n",
        "You might run into this problem, for example, **if you have a column that appears to be entirely numeric, but happens to contain spaces or commas.** If you upload data to particular SQL databases software with commas in a column full of numbers, that SQL database software will treat that column as non-numeric. \n",
        "\n",
        "Generally, numeric column types in various SQL databases do not support commas or currency symbols. To make things more complicated, SQL databases can store data in many different formats with different levels of precision.\n",
        "\n",
        "To see a list of data types, you can visit the website of each SQL database software, or at a glance, you can visit [this](https://www.w3schools.com/sql/sql_datatypes.asp).\n"
      ],
      "metadata": {
        "id": "by8yYPul9qGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "It's certainly best for data to be stored in its optimal format from the beginning, but if it isn't, you can always change it in your query. **It's particularly common for dates or numbers, for example, to be stored as strings.** This becomes problematic when you want to sum a column and you get an error because SQL is reading numbers as strings. \n",
        "\n",
        "```\n",
        "-- Convert one column\n",
        "ALTER TABLE table_name\n",
        "MODIFY column_name new_column_data_type\n",
        "```\n",
        "\n",
        "You can also convert data type at the time of querying so that it doesn't change original dataset. \n",
        "\n",
        "Synytax : `CONVERT(value, type)` or `CAST(value, type)`\n",
        "\n",
        "```\n",
        "-- Example : Convert a column\n",
        "SELECT CONVERT(founded_at, DATE)\n",
        "FROM crunchbase_companies_clean_data;\n",
        "\n",
        "-- Example : Convert a value\n",
        "SELECT CONVERT('01/03/12', DATE);\n",
        "Result: '2001-03-12'\n",
        "```"
      ],
      "metadata": {
        "id": "DhUiUonK-opy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "In our table, you can see in the table `crunchbase_companies_clean_data`, there is a column named `founded_at`. Let's check the result from this query : \n",
        "\n",
        "```\n",
        "SELECT *\n",
        "FROM crunchbase_companies_clean_data\n",
        "ORDER BY founded_at`\n",
        "```\n",
        "\n",
        "As you can see, the result is not ordered properly. Try, convert it into `DATE` and then re-query : \n",
        "\n",
        "```\n",
        "ALTER TABLE crunchbase_companies_clean_data MODIFY founded_at DATE\n",
        "\n",
        "SELECT *\n",
        "FROM crunchbase_companies_clean_data\n",
        "ORDER BY founded_at`\n",
        "```\n",
        "\n",
        "After we convert it into `DATE`, now we can see that the result is properly ordered."
      ],
      "metadata": {
        "id": "gGdqK2bVko9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## SQL Date Format"
      ],
      "metadata": {
        "id": "YniYwuH-Q0Ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're probably used to seeing dates formatted as MM-DD-YYYY or a similar, month-first format. It's not necessarily any worse than DD-MM-YYYY. The problem with both of these formats is that when they are stored as strings, they don't sort in chronological order. For example, here's a date field stored as a string. Because the month is listed first, the `ORDER BY` statement doesn't produce a chronological list:\n",
        "\n",
        "```\n",
        "SELECT permalink,\n",
        "       founded_at\n",
        "FROM crunchbase_companies_clean_data\n",
        "ORDER BY founded_at\n",
        "```\n",
        "You must convert it from string data-type to datetime data-type. Here's an example from the same table, but with a field that has a cleaned date. Note that the cleaned date field is actually stored as a string, but still sorts in chronological order anyway:\n",
        "\n",
        "```\n",
        "SELECT permalink,\n",
        "       founded_at,\n",
        "       founded_at_clean\n",
        "FROM crunchbase_companies_clean_data\n",
        "ORDER BY founded_at_clean\n",
        "```"
      ],
      "metadata": {
        "id": "-lym6BAD7li2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Crazy rules for dates and times\n",
        "\n",
        "Assuming you've got some dates properly stored as a `DATE` or `TIME` data type, you can do some pretty powerful things. Maybe you'd like to calculate a field of dates a week after an existing field. Or maybe you'd like to create a field that indicates how many days apart the values in two other date fields are. These are trivially simple, but it's important to keep in mind that the data type of your results will depend on exactly what you are doing to the dates.\n",
        "\n",
        "When you perform arithmetic on dates (such as subtracting one date from another), the results are often stored as the `interval` data type — a series of integers that represent a period of time. The following query uses date subtraction to determine how long it took companies to be acquired (unacquired companies and those without dates entered were filtered out). Note that because the `companies.founded_at_clean` column is stored as a string, it must be cast as a timestamp before it can be subtracted from another timestamp.\n",
        "\n",
        "```\n",
        "SELECT companies.permalink,\n",
        "       companies.founded_at_clean,\n",
        "       acquisitions.acquired_at_cleaned,\n",
        "       acquisitions.acquired_at_cleaned -\n",
        "         companies.founded_at_clean::timestamp AS time_to_acquisition\n",
        "FROM crunchbase_companies_clean_data companies\n",
        "JOIN crunchbase_acquisitions_clean_data acquisitions\n",
        "  ON acquisitions.company_permalink = companies.permalink\n",
        "WHERE founded_at_clean IS NOT NULL\n",
        "```\n",
        "\n",
        "In the example above, you can see that the `time_to_acquisition` column is an interval, not another date.\n",
        "\n",
        "You can introduce intervals using the `INTERVAL` function as well:\n",
        "\n",
        "```\n",
        "SELECT companies.permalink,\n",
        "       companies.founded_at_clean,\n",
        "       DATE_ADD(CONVERT(companies.founded_at_clean, datetime),  INTERVAL 1 WEEK) AS plus_one_week\n",
        "FROM crunchbase_companies_clean_data companies\n",
        "WHERE founded_at_clean IS NOT NULL\n",
        "```\n",
        "\n",
        "The interval is defined using plain-English terms like '10 seconds' or '5 months'. Also note that adding or subtracting a `date` column and an `interval` column results in another date column as in the above query.\n",
        "\n",
        "You can add the current time (at the time you run the query) into your code using the `NOW()` function:\n",
        "\n",
        "```\n",
        "SELECT companies.permalink,\n",
        "       companies.founded_at_clean,\n",
        "       NOW() - CONVERT(companies.founded_at_clean, DATETIME) AS founded_time_ago\n",
        "FROM crunchbase_companies_clean_data companies\n",
        "WHERE founded_at_clean IS NOT NULL\n",
        "```"
      ],
      "metadata": {
        "id": "rNzKu9CjjdI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Using SQL String Functions to Clean Data"
      ],
      "metadata": {
        "id": "rc_CFocq7ct7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lesson features data on San Francisco Crime Incidents for the 3-month period beginning November 1, 2013 and ending January 31, 2014. It was collected from the SF Data website on February 16, 2014. There is one row for each incident reported. Some field definitions: location is the GPS location of the incident, listed in decimal degrees, latitude first, longitude second. The two coordinates are also broken out into the lat and lon fields, respectively.\n",
        "\n",
        "```\n",
        "SELECT *\n",
        "FROM tutorial.sf_crime_incidents_2014_01\n",
        "```"
      ],
      "metadata": {
        "id": "E02ZBOzx7jFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Cleaning Strings\n",
        "\n",
        "`LEFT`, `RIGHT`, and `TRIM` are all used to select only certain elements of strings, but using them to select elements of a number or date will treat them as strings for the purpose of the function."
      ],
      "metadata": {
        "id": "mjPsIm2-tYN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### LEFT, RIGHT, and LENGTH\n",
        "\n",
        "Let's start with `LEFT`. You can use `LEFT` to pull a certain number of characters from the left side of a string and present them as a separate string. The syntax is `LEFT(string, number of characters)`.\n",
        "\n",
        "As a practical example, we can see that the date field in this dataset begins with a 10-digit date, and include the timestamp to the right of it. The following query pulls out only the date.\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       date,\n",
        "       LEFT(date, 10) AS cleaned_date\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```\n",
        "\n",
        "`RIGHT` does the same thing, but from the right side:\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       date,\n",
        "       LEFT(date, 10) AS cleaned_date,\n",
        "       RIGHT(date, 17) AS cleaned_time\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```\n",
        "\n",
        "`RIGHT` works well in this case because we know that the number of characters will be consistent across the entire date field. If it wasn't consistent, it's still possible to pull a string from the right side in a way that makes sense. \n",
        "\n",
        "The `LENGTH` function returns the length of a string. So `LENGTH(date)` will always return 28 in this dataset. Since we know that the first 10 characters will be the date, and they will be followed by a space (total 11 characters), we could represent the `RIGHT` function like this:\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       date,\n",
        "       LEFT(date, 10) AS cleaned_date,\n",
        "       RIGHT(date, LENGTH(date) - 11) AS cleaned_time\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```\n",
        "When using functions within other functions, it's important to remember that **the innermost functions will be evaluated first, followed by the functions that encapsulate them**."
      ],
      "metadata": {
        "id": "w3asrlQtAtw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### TRIM\n",
        "\n",
        "The `TRIM` function is used to remove characters from the beginning and end of a string. Here's an example:\n",
        "\n",
        "```\n",
        "SELECT location,\n",
        "       TRIM(both '(3' FROM location)\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```\n",
        "\n",
        "The `TRIM` function takes 3 arguments. First, you have to specify whether you want to remove characters from the beginning ('leading'), the end ('trailing'), or both ('both', as used above). Next you must specify all characters to be trimmed. Any characters included in the single quotes will be removed from both beginning, end, or both sides of the string. Finally, you must specify the text you want to trim using `FROM`."
      ],
      "metadata": {
        "id": "jhvoS2iOBlXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### POSITION and STRPOS\n",
        "\n",
        "`POSITION` allows you to specify a substring, then returns a numerical value equal to the character number (counting from left) where that substring first appears in the target string. For example, the following query will return the position of the character 'A' (case-sensitive) where it first appears in the `descript` field:\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       descript,\n",
        "       POSITION('A' IN descript) AS a_position\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```"
      ],
      "metadata": {
        "id": "tiCphZo3BfnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### SUBSTR\n",
        "\n",
        "`LEFT` and `RIGHT` both create substrings of a specified length, but they only do so starting from the sides of an existing string. If you want to start in the middle of a string, you can use `SUBSTR`. The syntax is `SUBSTR(*string*, *starting character position*, *# of characters*)`:\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       date,\n",
        "       SUBSTR(date, 6, 2) AS month\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```"
      ],
      "metadata": {
        "id": "tYb8ATv2DKsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### CONCAT\n",
        "\n",
        "You can combine strings from several columns together (and with hard-coded values) using `CONCAT`. Simply order the values you want to concatenate and separate them with commas. If you want to hard-code values, enclose them in single quotes. Here's an example:\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       day_of_week,\n",
        "       LEFT(date, 10) AS cleaned_date,\n",
        "       CONCAT(day_of_week, ', ', LEFT(date, 10)) AS day_and_date\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```"
      ],
      "metadata": {
        "id": "fP-Et0NaDhcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### Changing case with UPPER and LOWER\n",
        "\n",
        "Sometimes, you just don't want your data to look like it's screaming at you. \n",
        "* You can use **`LOWER` to force every character in a string to become lower-case**. \n",
        "* Similarly, you can use **`UPPER` to make all the letters appear in upper-case**:\n",
        "\n",
        "```\n",
        "SELECT incidnt_num,\n",
        "       address,\n",
        "       UPPER(address) AS address_upper,\n",
        "       LOWER(address) AS address_lower\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```\n",
        "\n",
        "There are a number of variations of these functions, as well as several other string functions not covered here. Different databases use subtle variations on these functions, so be sure to look up the appropriate database's syntax if you're connected to a private database."
      ],
      "metadata": {
        "id": "SQ7xjAswEO-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Turning dates into more useful dates\n",
        "\n",
        "Dates are some of the most commonly screwed-up formats in SQL. This can be the result of a few things:\n",
        "\n",
        "* The data was manipulated in Excel at some point, and the dates were changed to MM/DD/YYYY format or another format that is not compliant with SQL's strict standards.\n",
        "* The data was manually entered by someone who use whatever formatting convention he/she was most familiar with.\n",
        "* The date uses text (Jan, Feb, etc.) intsead of numbers to record months.\n",
        "\n",
        "Once you've got a well-formatted date field, you can manipulate in all sorts of interesting ways. To make the lesson a little cleaner, we'll use a different version of the crime incidents dataset that already has a nicely-formatted date field:\n",
        "\n",
        "```\n",
        "SELECT *\n",
        "FROM tutorial.sf_crime_incidents_cleandate\n",
        "```\n",
        "\n",
        "You've learned how to construct a date field, but what if you want to deconstruct one? You can use EXTRACT to pull the pieces apart one-by-one:\n",
        "\n",
        "```\n",
        "SELECT date,\n",
        "       EXTRACT(year FROM date) AS year,\n",
        "       EXTRACT(MONTH FROM date) AS month,\n",
        "       EXTRACT(DAY FROM date) AS day,\n",
        "       EXTRACT(HOUR FROM date) AS hour,\n",
        "       EXTRACT(MINUTE FROM date) AS minute,\n",
        "       EXTRACT(SECOND FROM date) AS second,\n",
        "       EXTRACT(QUARTER FROM date) AS quarter\n",
        "FROM sf_crime_incidents_2014_01;\n",
        "```\n",
        "\n",
        "What if you want to include today's date or time? You can instruct your query to pull the local date and time at the time the query is run using any number of functions. Interestingly, you can run them without a `FROM` clause:\n",
        "\n",
        "```\n",
        "SELECT CURRENT_DATE AS date,\n",
        "       CURRENT_TIME AS time,\n",
        "       CURRENT_TIMESTAMP AS timestamp,\n",
        "       LOCALTIME AS local_time,\n",
        "       LOCALTIMESTAMP AS local_timestamp,\n",
        "       NOW() AS now\n",
        "```\n",
        "\n",
        "As you can see, the different options vary in precision. You might notice that these times probably aren't actually your local time. If you run a current time function against a connected database, you might get a result in a different time zone.\n",
        "\n",
        "There is a lot function related to Date & Time. This is example those functions in [Maria DB](https://mariadb.com/kb/en/date-time-functions/)."
      ],
      "metadata": {
        "id": "p80DMSJqE0_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### COALESCE\n",
        "\n",
        "Occasionally, you will end up with a dataset that has some nulls that you'd prefer to contain actual values. This happens frequently in numerical data (displaying nulls as 0 is often preferable), and when performing outer joins that result in some unmatched rows. In cases like this, you can use `COALESCE` to replace the null values:\n",
        "\n",
        "```\n",
        "SELECT category,\n",
        "       resolution,\n",
        "       COALESCE(resolution, 'No Resolution')\n",
        "FROM sf_crime_incidents_2014_01\n",
        "```"
      ],
      "metadata": {
        "id": "RhehvYLeTU6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## SQL Window Functions\n",
        "\n",
        "This lesson uses data from Washington DC's Capital Bikeshare Program, (table `dc_bikeshare_q1_2012`) which publishes detailed trip-level historical data on their website. The data was downloaded in February, 2014, but is limited to data collected during the first quarter of 2012. Each row represents one ride. Most fields are self-explanatory, except `rider_type`: \n",
        "  * `Registered` indicates a monthly membership to the rideshare program, \n",
        "  * `Casual` incidates that the rider bought a 3-day pass. \n",
        "\n",
        "The `start_time` and `end_time` fields were cleaned up from their original forms to suit SQL date formatting—they are stored in this table as timestamps."
      ],
      "metadata": {
        "id": "opPFbxP8Tg0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intro to window functions\n",
        "\n",
        "A window function performs a calculation across a set of table rows that are somehow related to the current row. This is comparable to the type of calculation that can be done with an aggregate function. But unlike regular aggregate functions, use of a window function does not cause rows to become grouped into a single output row — the rows retain their separate identities. Behind the scenes, the window function is able to access more than just the current row of the query result.\n",
        "\n",
        "The most practical example of this is to calculate cumulative of field `duration_seconds` based on `start_time`:\n",
        "\n",
        "```\n",
        "SELECT duration_seconds,\n",
        "       SUM(duration_seconds) OVER (ORDER BY start_time) AS running_total\n",
        "FROM dc_bikeshare_q1_2012\n",
        "```\n",
        "\n",
        "You can see that the above query creates an aggregation (`running_total`) without using `GROUP BY`. Let's break down the syntax and see how it works."
      ],
      "metadata": {
        "id": "AzeHTAWNVUGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Basic windowing syntax\n",
        "\n",
        "The first part of the above aggregation, `SUM(duration_seconds)`, looks a lot like any other aggregation. Adding `OVER` designates it as a window function. You could read the above aggregation as \"take the sum of `duration_seconds` over the entire result set, in order by `start_time`.\"\n",
        "\n",
        "If you'd like to narrow the window from the entire dataset to individual groups within the dataset, you can use `PARTITION BY` to do so:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       SUM(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY start_time)\n",
        "         AS running_total\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```\n",
        "\n",
        "The above query groups and orders the query by `start_terminal`. Within each value of `start_terminal`, it is ordered by `start_time`, and the running total sums across the current row and all previous rows of `duration_seconds`. Scroll down until the `start_terminal` value changes and you will notice that `running_total` starts over. That's what happens when you group using `PARTITION BY`. In case you're still stumped by `ORDER BY`, it simply orders by the designated column(s) the same way the `ORDER BY` clause would, except that it treats every partition as separate. It also creates the running total—without `ORDER BY`, each value will simply be a sum of all the duration_seconds values in its respective `start_terminal`. Try running the above query without `ORDER BY` to get an idea:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       SUM(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal) AS start_terminal_total\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```\n",
        "\n",
        "The `ORDER` and `PARTITION` define what is referred to as the \"window\"—the ordered subset of data over which calculations are made.\n",
        "\n",
        "Note: You can't use window functions and standard aggregations in the same query. More specifically, you can't include window functions in a `GROUP BY` clause."
      ],
      "metadata": {
        "id": "1KtBD4jSVtJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### The usual suspects: SUM, COUNT, and AVG\n",
        "\n",
        "When using window functions, you can apply the same aggregates that you would under normal circumstances—`SUM`, `COUNT`, and `AVG`. The easiest way to understand these is to re-run the previous example with some additional functions. \n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       SUM(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal) AS running_total,\n",
        "       COUNT(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal) AS running_count,\n",
        "       AVG(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal) AS running_avg\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```\n",
        "\n",
        "Alternatively, the same functions with `ORDER BY`:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       SUM(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY start_time) AS running_total,\n",
        "       COUNT(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY start_time) AS running_count,\n",
        "       AVG(duration_seconds) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY start_time) AS running_avg\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```\n",
        "\n",
        "This next practice problem is very similar to the examples, so try modifying the above code rather than starting from scratch."
      ],
      "metadata": {
        "id": "CAacbOXgW7xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ROW_NUMBER\n",
        "\n",
        "`ROW_NUMBER()` does just what it sounds like—displays the number of a given row. It starts are 1 and numbers the rows according to the `ORDER BY` part of the window statement. `ROW_NUMBER()` does not require you to specify a variable within the parentheses:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       start_time,\n",
        "       duration_seconds,\n",
        "       ROW_NUMBER() OVER (ORDER BY start_time)\n",
        "                    AS row_number\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```\n",
        "\n",
        "Using the `PARTITION BY` clause will allow you to begin counting 1 again in each partition. The following query starts the count over again for each terminal:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       start_time,\n",
        "       duration_seconds,\n",
        "       ROW_NUMBER() OVER (PARTITION BY start_terminal\n",
        "                          ORDER BY start_time)\n",
        "                    AS row_number\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "```"
      ],
      "metadata": {
        "id": "V00Y2dt1XasK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NTILE\n",
        "\n",
        "You can use window functions to identify what percentile (or quartile, or any other subdivision) a given row falls into. The syntax is `NTILE(*# of buckets*)`. In this case, `ORDER BY` determines which column to use to determine the quartiles (or whatever number of 'tiles you specify). For example:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       NTILE(4) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY duration_seconds)\n",
        "          AS quartile,\n",
        "       NTILE(5) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY duration_seconds)\n",
        "         AS quintile\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "ORDER BY start_terminal, duration_seconds\n",
        "```"
      ],
      "metadata": {
        "id": "v0hANARMYFRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LAG and LEAD\n",
        "\n",
        "It can often be useful to compare rows to preceding or following rows, especially if you've got the data in an order that makes sense. You can use `LAG` or `LEAD` to create columns that pull values from other rows—all you need to do is enter which column to pull from and how many rows away you'd like to do the pull. `LAG` pulls from previous rows and `LEAD` pulls from following rows:\n",
        "\n",
        "In the following syntax, you can see previous and following rows per `start_terminal`. If the `start_terminal` only contains 1 row, you can seet both in `lag` column and `lead` column, it'll be filled by `NULL`.\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       LAG(duration_seconds, 1) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY duration_seconds) AS lag,\n",
        "       LEAD(duration_seconds, 1) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY duration_seconds) AS lead\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "ORDER BY start_terminal, duration_seconds\n",
        "```\n",
        "\n",
        "\n",
        "This is especially useful if you want to calculate differences between rows:\n",
        "\n",
        "```\n",
        "SELECT start_terminal,\n",
        "       duration_seconds,\n",
        "       duration_seconds -LAG(duration_seconds, 1) OVER\n",
        "         (PARTITION BY start_terminal ORDER BY duration_seconds)\n",
        "         AS difference\n",
        "FROM dc_bikeshare_q1_2012\n",
        "WHERE start_time < '2012-01-08'\n",
        "ORDER BY start_terminal, duration_seconds\n",
        "```\n",
        "\n",
        "The first row of the `difference` column is null because there is no previous row from which to pull. Similarly, using `LEAD` will create nulls at the end of the dataset. If you'd like to make the results a bit cleaner, you can wrap it in an outer query to remove nulls:\n",
        "\n",
        "```\n",
        "SELECT *\n",
        "  FROM (\n",
        "    SELECT start_terminal,\n",
        "           duration_seconds,\n",
        "           duration_seconds -LAG(duration_seconds, 1) OVER\n",
        "             (PARTITION BY start_terminal ORDER BY duration_seconds)\n",
        "             AS difference\n",
        "      FROM dc_bikeshare_q1_2012\n",
        "     WHERE start_time < '2012-01-08'\n",
        "     ORDER BY start_terminal, duration_seconds\n",
        "       ) sub\n",
        " WHERE sub.difference IS NOT NULL\n",
        "```"
      ],
      "metadata": {
        "id": "kDbgbGClYykx"
      }
    }
  ]
}