{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "nav_menu": {
      "height": "252px",
      "width": "333px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "d2pm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r-7bAgHq_T"
      },
      "source": [
        "# Week 2: Day 2 PM // Ensemble Learning Pt.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc96CXB8Hq_W"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOIIxp0EHq_X"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyvluSGaHq_Y"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ensembles\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH9XvNvYBQlp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLlsNPNIHq_a"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9n5tearHq_b"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
        "    n_estimators=500, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq01JTUKHq_c"
      },
      "source": [
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr2L_VpwHq_d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5pgotSUHq_e"
      },
      "source": [
        "np.sum(y_pred == y_pred_rf) / len(y_pred)  # very similar predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5nsl8nPHq_g"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlj9mLgiHq_h"
      },
      "source": [
        "rnd_clf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLm83qnvBrLp"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.5, contour=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
        "    if contour:\n",
        "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
        "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkQ4IuzTHq_i"
      },
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "for i in range(15):\n",
        "    tree_clf = DecisionTreeClassifier(max_leaf_nodes=16, random_state=42 + i)\n",
        "    indices_with_replacement = np.random.randint(0, len(X_train), len(X_train))\n",
        "    tree_clf.fit(X[indices_with_replacement], y[indices_with_replacement])\n",
        "    plot_decision_boundary(tree_clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.02, contour=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xV01v7RHq_i"
      },
      "source": [
        "### Out-of-Bag evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGk_b1fVHq_j"
      },
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    bootstrap=True, oob_score=True, random_state=40)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewvTqhZHq_j"
      },
      "source": [
        "bag_clf.oob_decision_function_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKgigC2QHq_k"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7GxlWi7Hq_k"
      },
      "source": [
        "### Feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPVsf1Q1Hq_l"
      },
      "source": [
        "**Warning:** since Scikit-Learn 0.24, `fetch_openml()` returns a Pandas `DataFrame` by default. To avoid this and keep the same code as in the book, we use `as_frame=False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKue02d5Hq_l"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.target = mnist.target.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OTcW933Hq_l"
      },
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rnd_clf.fit(mnist[\"data\"], mnist[\"target\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn9rpz54Hq_m"
      },
      "source": [
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.hot,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPpUp5WvHq_m"
      },
      "source": [
        "plot_digit(rnd_clf.feature_importances_)\n",
        "\n",
        "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
        "cbar.ax.set_yticklabels(['Not important', 'Very important'])\n",
        "\n",
        "save_fig(\"mnist_feature_importance_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug4g6XU-Hq_n"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv8Eu9sDHq_n"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Q_zJa7Hq_o"
      },
      "source": [
        "plot_decision_boundary(ada_clf, X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ook9TQxKHq_o"
      },
      "source": [
        "m = len(X_train)\n",
        "\n",
        "fix, axes = plt.subplots(ncols=2, figsize=(10,4), sharey=True)\n",
        "for subplot, learning_rate in ((0, 1), (1, 0.5)):\n",
        "    sample_weights = np.ones(m) / m\n",
        "    plt.sca(axes[subplot])\n",
        "    for i in range(5):\n",
        "        svm_clf = SVC(kernel=\"rbf\", C=0.2, gamma=0.6, random_state=42)\n",
        "        svm_clf.fit(X_train, y_train, sample_weight=sample_weights * m)\n",
        "        y_pred = svm_clf.predict(X_train)\n",
        "\n",
        "        r = sample_weights[y_pred != y_train].sum() / sample_weights.sum() # equation 7-1\n",
        "        alpha = learning_rate * np.log((1 - r) / r) # equation 7-2\n",
        "        sample_weights[y_pred != y_train] *= np.exp(alpha) # equation 7-3\n",
        "        sample_weights /= sample_weights.sum() # normalization step\n",
        "\n",
        "        plot_decision_boundary(svm_clf, X, y, alpha=0.2)\n",
        "        plt.title(\"learning_rate = {}\".format(learning_rate), fontsize=16)\n",
        "    if subplot == 0:\n",
        "        plt.text(-0.75, -0.95, \"1\", fontsize=14)\n",
        "        plt.text(-1.05, -0.95, \"2\", fontsize=14)\n",
        "        plt.text(1.0, -0.95, \"3\", fontsize=14)\n",
        "        plt.text(-1.45, -0.5, \"4\", fontsize=14)\n",
        "        plt.text(1.36,  -0.95, \"5\", fontsize=14)\n",
        "    else:\n",
        "        plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"boosting_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2DpNeAHq_p"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRU6NUwTHq_p"
      },
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiY_eAG8Hq_p"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDvh6oe7Hq_p"
      },
      "source": [
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QVaLFDeHq_p"
      },
      "source": [
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aql2hRC8Hq_q"
      },
      "source": [
        "X_new = np.array([[0.8]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLk3KbhwHq_q"
      },
      "source": [
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-C0A3paHq_q"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-NHgt7uHq_q"
      },
      "source": [
        "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500)\n",
        "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
        "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
        "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
        "    if label or data_label:\n",
        "        plt.legend(loc=\"upper center\", fontsize=16)\n",
        "    plt.axis(axes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8mPVHAkHq_q"
      },
      "source": [
        "plt.figure(figsize=(11,11))\n",
        "\n",
        "plt.subplot(321)\n",
        "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h_1(x_1)$\", style=\"g-\", data_label=\"Training set\")\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "plt.title(\"Residuals and tree predictions\", fontsize=16)\n",
        "\n",
        "plt.subplot(322)\n",
        "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1)$\", data_label=\"Training set\")\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "plt.title(\"Ensemble predictions\", fontsize=16)\n",
        "\n",
        "plt.subplot(323)\n",
        "plot_predictions([tree_reg2], X, y2, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_2(x_1)$\", style=\"g-\", data_style=\"k+\", data_label=\"Residuals\")\n",
        "plt.ylabel(\"$y - h_1(x_1)$\", fontsize=16)\n",
        "\n",
        "plt.subplot(324)\n",
        "plot_predictions([tree_reg1, tree_reg2], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1)$\")\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "\n",
        "plt.subplot(325)\n",
        "plot_predictions([tree_reg3], X, y3, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_3(x_1)$\", style=\"g-\", data_style=\"k+\")\n",
        "plt.ylabel(\"$y - h_1(x_1) - h_2(x_1)$\", fontsize=16)\n",
        "plt.xlabel(\"$x_1$\", fontsize=16)\n",
        "\n",
        "plt.subplot(326)\n",
        "plot_predictions([tree_reg1, tree_reg2, tree_reg3], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1) + h_3(x_1)$\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=16)\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "\n",
        "save_fig(\"gradient_boosting_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQVmDinNHq_r"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
        "gbrt.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIa4tt3GHq_r"
      },
      "source": [
        "gbrt_slow = GradientBoostingRegressor(max_depth=2, n_estimators=200, learning_rate=0.1, random_state=42)\n",
        "gbrt_slow.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqSAyedqHq_r"
      },
      "source": [
        "fix, axes = plt.subplots(ncols=2, figsize=(10,4), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"Ensemble predictions\")\n",
        "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt.learning_rate, gbrt.n_estimators), fontsize=14)\n",
        "plt.xlabel(\"$x_1$\", fontsize=16)\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_predictions([gbrt_slow], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
        "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt_slow.learning_rate, gbrt_slow.n_estimators), fontsize=14)\n",
        "plt.xlabel(\"$x_1$\", fontsize=16)\n",
        "\n",
        "save_fig(\"gbrt_learning_rate_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFyWpkguHq_r"
      },
      "source": [
        "### Gradient Boosting with Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22G1idkrHq_s"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kpy6WVXHq_s"
      },
      "source": [
        "min_error = np.min(errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smanqd4kHq_s"
      },
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(errors, \"b.-\")\n",
        "plt.plot([bst_n_estimators, bst_n_estimators], [0, min_error], \"k--\")\n",
        "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
        "plt.plot(bst_n_estimators, min_error, \"ko\")\n",
        "plt.text(bst_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
        "plt.axis([0, 120, 0, 0.01])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Error\", fontsize=16)\n",
        "plt.title(\"Validation error\", fontsize=14)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
        "plt.title(\"Best model (%d trees)\" % bst_n_estimators, fontsize=14)\n",
        "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
        "plt.xlabel(\"$x_1$\", fontsize=16)\n",
        "\n",
        "save_fig(\"early_stopping_gbrt_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVy8W1wQHq_s"
      },
      "source": [
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 120):\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)\n",
        "    if val_error < min_val_error:\n",
        "        min_val_error = val_error\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break  # early stopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUPdS8D8Hq_t"
      },
      "source": [
        "print(gbrt.n_estimators)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-a9-u9Hq_t"
      },
      "source": [
        "print(\"Minimum validation MSE:\", min_val_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVTkpr3THq_t"
      },
      "source": [
        "### Using XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk2G2OonHq_t"
      },
      "source": [
        "try:\n",
        "    import xgboost\n",
        "except ImportError as ex:\n",
        "    print(\"Error: the xgboost library is not installed.\")\n",
        "    xgboost = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1PKAS8pHq_t"
      },
      "source": [
        "if xgboost is not None:  # not shown in the book\n",
        "    xgb_reg = xgboost.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
        "    xgb_reg.fit(X_train, y_train)\n",
        "    y_pred = xgb_reg.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred) # Not shown\n",
        "    print(\"Validation MSE:\", val_error)           # Not shown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNDdrSukHq_t"
      },
      "source": [
        "if xgboost is not None:  # not shown in the book\n",
        "    xgb_reg.fit(X_train, y_train,\n",
        "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
        "    y_pred = xgb_reg.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)  # Not shown\n",
        "    print(\"Validation MSE:\", val_error)            # Not shown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp1H3eoDHq_u"
      },
      "source": [
        "%timeit xgboost.XGBRegressor(objective='reg:squarederror').fit(X_train, y_train) if xgboost is not None else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc6njddhHq_u"
      },
      "source": [
        "%timeit GradientBoostingRegressor().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}